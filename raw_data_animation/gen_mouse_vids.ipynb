{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcs + Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "#-------------------------- Standard Imports --------------------------#\n",
    "import kdephys as kde\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import acr\n",
    "from acr.plots import pub, lrg\n",
    "from acr.utils import NNXR_GRAY, SOM_BLUE\n",
    "lrg()\n",
    "plt.style.use('fast')\n",
    "from scipy import stats\n",
    "# ---------------------------- EXTRAS --------------------------------#\n",
    "from kdephys.plot.main import _title, bp_plot\n",
    "import kdephys.utils.spectral as sp\n",
    "bands = sp.bands\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.collections import PathCollection\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def _plt_style():\n",
    "    plt.style.use('fast')\n",
    "    plt.style.use('/home/kdriessen/gh_master/kdephys/kdephys/plot/acr_plots.mplstyle')\n",
    "    return\n",
    "pu = acr.utils.import_publication_functions('/home/kdriessen/gh_master/PUBLICATION__ACR/pub_utils.py', 'pu')\n",
    "dag = acr.utils.import_publication_functions('/home/kdriessen/gh_master/PUBLICATION__ACR/data_agg.py', 'dag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "def get_video_framerate(video_path: str) -> float:\n",
    "    \"\"\"Gets the framerate of a video using ffprobe.\"\"\"\n",
    "    if not shutil.which(\"ffprobe\"):\n",
    "        print(\"Error: ffprobe not found. Please install ffmpeg.\")\n",
    "        return None\n",
    "    \n",
    "    command = [\n",
    "        \"ffprobe\",\n",
    "        \"-v\", \"error\",\n",
    "        \"-select_streams\", \"v:0\",\n",
    "        \"-show_entries\", \"stream=r_frame_rate\",\n",
    "        \"-of\", \"default=noprint_wrappers=1:nokey=1\",\n",
    "        video_path,\n",
    "    ]\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error getting framerate: {result.stderr}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        num, den = map(int, result.stdout.strip().split('/'))\n",
    "        return num / den\n",
    "    except (ValueError, ZeroDivisionError) as e:\n",
    "        print(f\"Could not parse framerate from ffprobe output: '{result.stdout.strip()}' due to {e}\")\n",
    "        return None\n",
    "\n",
    "def slice_vid_gem(video_path: str, start_time: float, end_time: float, output_path: str):\n",
    "    \"\"\"\n",
    "    Slices a video file from start_time to end_time using ffmpeg and saves it to output_path.\n",
    "    This version uses libx264 for better compatibility.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        start_time (float): Start time in seconds.\n",
    "        end_time (float): End time in seconds.\n",
    "        output_path (str): Path to save the sliced video.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Error: Video file not found at {video_path}\")\n",
    "        return\n",
    "\n",
    "    if not shutil.which(\"ffmpeg\"):\n",
    "        print(\"Error: ffmpeg not found. Please install ffmpeg.\")\n",
    "        return\n",
    "        \n",
    "    fps = get_video_framerate(video_path)\n",
    "    if fps is None:\n",
    "        return\n",
    "        \n",
    "    duration = end_time - start_time\n",
    "    total_frames_in_slice = int(duration * fps)\n",
    "\n",
    "    print(f\"Original framerate: {fps:.2f} FPS\")\n",
    "    print(f\"Total frames in new slice: {total_frames_in_slice}\")\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", video_path,\n",
    "        \"-ss\", str(start_time),\n",
    "        \"-to\", str(end_time),\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-c:a\", \"aac\",\n",
    "        \"-preset\", \"fast\",\n",
    "        \"-crf\", \"0\",\n",
    "        output_path,\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nRunning ffmpeg command:\\n{' '.join(command)}\\n\")\n",
    "    \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error slicing video with ffmpeg:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(f\"Sliced video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check + Animate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "times\n",
    "\n",
    "OFF_induction --> 16854\n",
    "\n",
    "SD-wake --> 92\n",
    "\n",
    "BL-sleep --> 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 'ACR_25'\n",
    "exp = 'swi'\n",
    "\n",
    "#---------------- Adjust Parameters Here -----------------# \n",
    "stores = ['NNXo', 'NNXr']\n",
    "rel_state='NREM'\n",
    "#---------------------------------------------------------#\n",
    "notebook_save_root = '/Volumes/opto_loc/Data/ACR_PROJECT_MATERIALS/plots_presentations_etc/paper_figures/animations/raw_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = 'swi-bl'\n",
    "root_path = acr.io.acr_path(subject, rec)\n",
    "for f in os.listdir(root_path):\n",
    "    if f.endswith('.avi'):\n",
    "        path_to_video = os.path.join(root_path, f)\n",
    "path_to_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'bl_sleep'\n",
    "output_path = f'{notebook_save_root}/{video_name}.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_vid_gem(path_to_video, start_time=640, end_time=650, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- subject_info + Hypno -----------------------------------------\n",
    "h = acr.io.load_hypno_full_exp(subject, exp)\n",
    "hd = acr.hypnogram_utils.create_acr_hyp_dict(subject, exp)\n",
    "si = acr.info_pipeline.load_subject_info(subject)\n",
    "sort_ids = [f'{exp}-{store}' for store in stores]\n",
    "recordings = acr.info_pipeline.get_exp_recs(subject, exp)\n",
    "stim_store = si['stim-exps'][exp][0]\n",
    "\n",
    "sd_true_start, stim_start, stim_end, rebound_start, full_exp_start = acr.info_pipeline.get_sd_exp_landmarks(subject, exp, update=True)\n",
    "\n",
    "\n",
    "mua = acr.mua.load_concat_peaks_df(subject, exp)\n",
    "fp = acr.io.load_concat_raw_data(subject, recordings)\n",
    "pon, poff = acr.stim.get_individual_pulse_times(subject, exp)\n",
    "\n",
    "bindf = dag.load_binned_off_df(subject, exp, count_res='1ms', channel_threshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_name = 'OFF_induction'\n",
    "probe_to_animate = 'NNXo'\n",
    "start_time = 16854\n",
    "duration = '10s'\n",
    "rec = 'swi'\n",
    "st = acr.utils.dt_from_tdt(subject, rec, start_time)\n",
    "col = SOM_BLUE if probe_to_animate == 'NNXo' else NNXR_GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check raster plot\n",
    "m2p = mua.prb(probe_to_animate).ts(st, st+pd.Timedelta(duration)).to_pandas()\n",
    "pon2p = pon[(pon>=st)&(pon<st+pd.Timedelta(duration))]\n",
    "poff2p = poff[(poff>st)&(poff<=st+pd.Timedelta(duration))]\n",
    "\n",
    "f, ax = simple_raster(m2p, pon2p, poff2p, color=col, figsize=(28, 4))\n",
    "shade_oodf(ax, bindf.prb(probe_to_animate).oots(st, st+pd.Timedelta(duration)), off_color='red', on_color='green', alpha=0.5, single_ax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limits = pickle.load(open(f'{subject}_{exp}_nnxo_lims.pkl', 'rb'))\n",
    "ylim = (-1340, 1260)\n",
    "limits = [ylim for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE TRACES TO BE ANIMATED\n",
    "plt.rcParams['ytick.left'] = False\n",
    "fp2p = fp.prb(probe_to_animate).ts(st, st+pd.Timedelta(duration))\n",
    "\n",
    "data = fp2p.data.T\n",
    "times = fp2p.datetime.data\n",
    "f, ax =quick_trace_plot(data, times, pon2p, poff2p)\n",
    "for a in ax:\n",
    "    a.set_xlim(times[0], times[-1])\n",
    "    a.set_ylim(ylim[0], ylim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2p = fp.prb(probe_to_animate).ts(st, st+pd.Timedelta(duration))\n",
    "data = fp2p.data.T\n",
    "times = fp2p.datetime.data\n",
    "pon2p = pon[(pon>=st)&(pon<st+pd.Timedelta(duration))]\n",
    "poff2p = poff[(poff>st)&(poff<=st+pd.Timedelta(duration))]\n",
    "\n",
    "\n",
    "# Create the animation\n",
    "trace_anim = animated_trace_numpy(\n",
    "    data=data,\n",
    "    times=times,\n",
    "    stim_starts=pon2p,\n",
    "    stim_ends=poff2p,\n",
    "    color=col,\n",
    "    fps=30,\n",
    "    duration=int(duration.split('s')[0]),\n",
    "    save_path=f'{notebook_save_root}/{anim_name}--LFP--{probe_to_animate}.mov',\n",
    "    ylims=limits\n",
    ")\n",
    "\n",
    "# To display in the notebook instead of saving\n",
    "# HTML(trace_anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data for raster plot\n",
    "m2p = mua.prb(probe_to_animate).ts(st, st+pd.Timedelta(duration)).to_pandas()\n",
    "pon2p = pon[(pon>=st)&(pon<st+pd.Timedelta(duration))]\n",
    "poff2p = poff[(poff>st)&(poff<=st+pd.Timedelta(duration))]\n",
    "# try using the total duraiton of the field potential data\n",
    "timespd = pd.to_datetime(times)\n",
    "tr = (timespd.max() - timespd.min()).total_seconds()\n",
    "\n",
    "# Create the animated raster plot\n",
    "# Generate the animation - adjust parameters as needed\n",
    "anim = animated_raster(\n",
    "    data=m2p, \n",
    "    stim_start=pon2p, \n",
    "    stim_ends=poff2p, \n",
    "    color=col, \n",
    "    figsize=(14, 2),\n",
    "    fps=30,\n",
    "    duration=int(duration.split('s')[0]),  # Match the 7s data duration\n",
    "    save_path=f'{notebook_save_root}/{anim_name}--RASTER--{probe_to_animate}.mov',  # Comment out to preview instead of saving\n",
    "    trange=tr\n",
    ")\n",
    "\n",
    "# Display the animation in the notebook\n",
    "# HTML(anim.to_jshtml())\n",
    "\n",
    "# Uncomment the above line to display the animation in the notebook\n",
    "# Or use the save_path parameter to save to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_to_animate = 'NNXr'\n",
    "col = SOM_BLUE if probe_to_animate == 'NNXo' else NNXR_GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp2p = fp.prb(probe_to_animate).ts(st, st+pd.Timedelta(duration))\n",
    "data = fp2p.data.T\n",
    "times = fp2p.datetime.data\n",
    "pon2p = pon[(pon>=st)&(pon<st+pd.Timedelta(duration))]\n",
    "poff2p = poff[(poff>st)&(poff<=st+pd.Timedelta(duration))]\n",
    "\n",
    "\n",
    "# Create the animation\n",
    "trace_anim = animated_trace_numpy(\n",
    "    data=data,\n",
    "    times=times,\n",
    "    stim_starts=pon2p,\n",
    "    stim_ends=poff2p,\n",
    "    color=col,\n",
    "    fps=30,\n",
    "    duration=int(duration.split('s')[0]),\n",
    "    save_path=f'{notebook_save_root}/{anim_name}--LFP--{probe_to_animate}.mov',\n",
    "    ylims=limits\n",
    ")\n",
    "\n",
    "# To display in the notebook instead of saving\n",
    "# HTML(trace_anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data for raster plot\n",
    "m2p = mua.prb(probe_to_animate).ts(st, st+pd.Timedelta(duration)).to_pandas()\n",
    "pon2p = pon[(pon>=st)&(pon<st+pd.Timedelta(duration))]\n",
    "poff2p = poff[(poff>st)&(poff<=st+pd.Timedelta(duration))]\n",
    "# try using the total duraiton of the field potential data\n",
    "timespd = pd.to_datetime(times)\n",
    "tr = (timespd.max() - timespd.min()).total_seconds()\n",
    "\n",
    "# Create the animated raster plot\n",
    "# Generate the animation - adjust parameters as needed\n",
    "anim = animated_raster(\n",
    "    data=m2p, \n",
    "    stim_start=pon2p, \n",
    "    stim_ends=poff2p, \n",
    "    color=col, \n",
    "    figsize=(14, 2),\n",
    "    fps=30,\n",
    "    duration=int(duration.split('s')[0]),  # Match the 7s data duration\n",
    "    save_path=f'{notebook_save_root}/{anim_name}--RASTER--{probe_to_animate}.mov',  # Comment out to preview instead of saving\n",
    "    trange=tr\n",
    ")\n",
    "\n",
    "# Display the animation in the notebook\n",
    "# HTML(anim.to_jshtml())\n",
    "\n",
    "# Uncomment the above line to display the animation in the notebook\n",
    "# Or use the save_path parameter to save to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generates the pickle files with ylim values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animated_trace_numpy(data, times, stim_starts, stim_ends, color=SOM_BLUE, \n",
    "                         hspace=-0.6, figsize=(28, 10), fps=30, duration=7, \n",
    "                         save_path=None, ylims=None):\n",
    "    \"\"\"\n",
    "    Create an animated plot of neural traces with stimulus overlays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        Raw data to plot, of shape (n_channels, n_samples)\n",
    "    times : np.ndarray\n",
    "        Times of the data, of shape (n_samples,)\n",
    "    stim_starts : list-like\n",
    "        Start times of stimulations\n",
    "    stim_ends : list-like\n",
    "        End times of stimulations\n",
    "    color : str, optional\n",
    "        Color of the traces, by default SOM_BLUE\n",
    "    hspace : float, optional\n",
    "        Space between traces, by default -0.6\n",
    "    figsize : tuple, optional\n",
    "        Size of the figure, by default (28, 10)\n",
    "    fps : int, optional\n",
    "        Frames per second for the animation, by default 30\n",
    "    duration : float, optional\n",
    "        Duration of the animation in seconds, by default 7\n",
    "    save_path : str, optional\n",
    "        Path to save the animation, by default None\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    anim : matplotlib.animation.Animation\n",
    "        The animation object\n",
    "    \"\"\"\n",
    "    # Set up figure and axes\n",
    "    f, axes = plt.subplots(data.shape[0], 1, figsize=figsize)\n",
    "    if data.shape[0] == 1:\n",
    "        axes = [axes]  # Make iterable if only one channel\n",
    "    \n",
    "    plt.subplots_adjust(hspace=hspace)\n",
    "    \n",
    "    # Style settings\n",
    "    plt.rcParams['ytick.left'] = False\n",
    "    plt.rcParams['axes.spines.bottom'] = False\n",
    "    plt.rcParams['axes.spines.left'] = False\n",
    "    plt.rcParams['axes.spines.right'] = False\n",
    "    plt.rcParams['axes.spines.top'] = False\n",
    "    \n",
    "    # Convert times to numeric if they are datetime objects\n",
    "    if isinstance(times[0], pd.Timestamp):\n",
    "        start_time = times[0]\n",
    "        numeric_times = np.array([(t - start_time).total_seconds() for t in times])\n",
    "        stim_starts_sec = np.array([(t - start_time).total_seconds() for t in stim_starts])\n",
    "        stim_ends_sec = np.array([(t - start_time).total_seconds() for t in stim_ends])\n",
    "    else:\n",
    "        # Assuming they're already numeric\n",
    "        numeric_times = times\n",
    "        start_time = times[0]\n",
    "        stim_starts_sec = np.array([t for t in stim_starts])\n",
    "        stim_ends_sec = np.array([t for t in stim_ends])\n",
    "    \n",
    "    # Time range for the animation\n",
    "    time_range = numeric_times[-1] - numeric_times[0]\n",
    "    \n",
    "    # Calculate y-axis limits for each channel\n",
    "    nnxo_lims = []\n",
    "    y_padding = .001  # Add 10% padding to y limits\n",
    "    for i, ax in enumerate(axes):\n",
    "        channel_data = data[i, :]\n",
    "        y_min = np.min(channel_data)\n",
    "        y_max = np.max(channel_data)\n",
    "        y_range = y_max - y_min\n",
    "        nnxo_lims.append((y_min, y_max))\n",
    "        # Set y limits with padding\n",
    "        ax.set_ylim(y_min - y_range * y_padding, y_max + y_range * y_padding)\n",
    "        \n",
    "        # Set x limits\n",
    "        if isinstance(times[0], pd.Timestamp):\n",
    "            ax.set_xlim(times[0], times[-1])\n",
    "        else:\n",
    "            ax.set_xlim(numeric_times[0], numeric_times[-1])\n",
    "            \n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Define the pickle file path\n",
    "    pickle_path = f\"{subject}_{exp}_nnxo_lims.pkl\"\n",
    "    \n",
    "    # Save the nnxo_lims list to the pickle file\n",
    "    with open(pickle_path, 'wb') as f:\n",
    "        pickle.dump(nnxo_lims, f)\n",
    "    \n",
    "    # Create empty line objects for each channel\n",
    "    lines = []\n",
    "    for i in range(data.shape[0]):\n",
    "        line, = axes[i].plot([], [], color=color, lw=1)\n",
    "        lines.append(line)\n",
    "    \n",
    "    # Create empty spans to track added spans\n",
    "    spans = []\n",
    "    \n",
    "    # Precompute stimulus span coordinates for all channels\n",
    "    stim_span_info = []\n",
    "    for start, end in zip(stim_starts, stim_ends):\n",
    "        stim_span_info.append((start, end))\n",
    "    \n",
    "    # Number of frames for the animation\n",
    "    n_frames = int(fps * duration)\n",
    "    \n",
    "    def init():\n",
    "        # Initialize empty lines\n",
    "        for line in lines:\n",
    "            line.set_data([], [])\n",
    "        return lines\n",
    "    \n",
    "    def update(frame):\n",
    "        # Calculate current time based on frame number\n",
    "        print(frame)\n",
    "        current_progress = frame / n_frames\n",
    "        current_idx = min(int(current_progress * len(numeric_times)), len(numeric_times) - 1)\n",
    "        \n",
    "        # Update each line with data up to the current time\n",
    "        for i, line in enumerate(lines):\n",
    "            if isinstance(times[0], pd.Timestamp):\n",
    "                line.set_data(times[:current_idx+1], data[i, :current_idx+1])\n",
    "            else:\n",
    "                line.set_data(numeric_times[:current_idx+1], data[i, :current_idx+1])\n",
    "        \n",
    "        # Add stimulus spans that should be visible by this time\n",
    "        current_time = numeric_times[current_idx]\n",
    "        artists = lines.copy()\n",
    "        \n",
    "        # Check which stimuli should be visible and add them if not already added\n",
    "        for i, (start, end) in enumerate(zip(stim_starts_sec, stim_ends_sec)):\n",
    "            # Create a unique identifier for this span\n",
    "            span_id = f\"span_{i}\"\n",
    "            \n",
    "            # If current time has passed the start of this stimulus and we haven't added it yet\n",
    "            if current_time >= start and not any(s[0] == span_id for s in spans):\n",
    "                # Add the span to all axes\n",
    "                for ax_idx, ax in enumerate(axes):\n",
    "                    # Create the span\n",
    "                    span = ax.axvspan(\n",
    "                        stim_span_info[i][0],  # Use original time format\n",
    "                        stim_span_info[i][1],  # Use original time format\n",
    "                        color='cornflowerblue',\n",
    "                        ymin=0.325,\n",
    "                        ymax=0.712,\n",
    "                        alpha=0.5\n",
    "                    )\n",
    "                    \n",
    "                    # Track this span with its ID\n",
    "                    spans.append((span_id, span))\n",
    "                    artists.append(span)\n",
    "        \n",
    "        # Add all existing spans to the artists list\n",
    "        for _, span in spans:\n",
    "            if span not in artists:\n",
    "                artists.append(span)\n",
    "        \n",
    "        return artists\n",
    "    \n",
    "    # Create the animation\n",
    "    anim = animation.FuncAnimation(\n",
    "        f, update, frames=n_frames, init_func=init, blit=True, interval=1000/fps\n",
    "    )\n",
    "    \n",
    "    if save_path:\n",
    "        # Save as video file\n",
    "        anim.save(save_path, writer='ffmpeg', fps=fps)\n",
    "        plt.close(f)\n",
    "    \n",
    "    return anim\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "off_ind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
